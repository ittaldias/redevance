{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2KBbD4Z0LDS"
      },
      "source": [
        "## Importation librairie et donnée\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3k7HF55XhAyX"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "# Chemin du dossier dans votre Google Drive\n",
        "chemin_dossier_pln_janvier = '/content/drive/My Drive/data/stan_janvier_2024'\n",
        "chemin_dossier_pln_mars = '/content/drive/My Drive/data/stan_mars_2024'\n",
        "chemin_dossier_abacus = '/content/drive/My Drive/data/ABACUS'\n",
        "chemin_dossier_table_systeme = '/content/drive/My Drive/data/TABLE_SYSTEME'\n",
        "chemin_dossier_table_fusion = '/content/drive/My Drive/data/fusion_radar'\n",
        "\n",
        "# Liste des fichiers dans le dossier\n",
        "contenu_dossier_pln_janvier = os.listdir(chemin_dossier_pln_janvier)\n",
        "contenu_dossier_pln_mars = os.listdir(chemin_dossier_pln_mars)\n",
        "contenu_dossier_abacus = os.listdir(chemin_dossier_abacus)\n",
        "contenu_dossier_table_systeme = os.listdir(chemin_dossier_table_systeme)\n",
        "contenu_dossier_table_fusion = os.listdir(chemin_dossier_table_fusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SGQ3EKfQyzr",
        "outputId": "a9cd1deb-7d0b-4ab8-f5e9-b365d0f460f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ONd4G0aRVMQO"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', 150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f84mPxYzOJ4X"
      },
      "outputs": [],
      "source": [
        "def read_and_process_file(fichier_a_deposee):\n",
        "    vol_prevu = []\n",
        "    vol_fini = []\n",
        "    vol_termine = []\n",
        "    tableau_vol = {}\n",
        "    tableaux_vol = []\n",
        "    iter = 0\n",
        "    flag82 = False\n",
        "    hneg = False\n",
        "    compt82 = 0\n",
        "    num81 = 0\n",
        "    prevu = False\n",
        "    termine = False\n",
        "    final = False\n",
        "    complet = 0\n",
        "    output = pd.DataFrame()\n",
        "    compteur = 0\n",
        "    tableau_vol = {}\n",
        "    compteurCcr = 0\n",
        "\n",
        "    with open(fichier_a_deposee, 'r') as fichier:\n",
        "        for i, ligne in enumerate(fichier):\n",
        "            words = ligne.split()\n",
        "            if words[0] == \"02\":\n",
        "                date_str = words[1]\n",
        "                date_obj = datetime.strptime(date_str, \"%d-%m-%Y\")\n",
        "                date_fichier = date_obj.timetuple().tm_yday\n",
        "            if words[0] == \"05\":\n",
        "                if tableau_vol:\n",
        "                    tableau_vol[\"isPrevu\"] = isprevu\n",
        "                    tableau_vol[\"isRealise\"] = isrealise\n",
        "                    tableau_vol[\"isFinal\"] = isfinal\n",
        "                    df_dictionary = pd.DataFrame([tableau_vol])\n",
        "                    output = pd.concat([output, df_dictionary], ignore_index=True)\n",
        "                tableau_vol = {}\n",
        "                isprevu = False\n",
        "                isrealise = False\n",
        "                isfinal = False\n",
        "                is81 = False\n",
        "                is82 = False\n",
        "                balise = ''\n",
        "                hneg = False\n",
        "                flag82 = False\n",
        "                etat = ''\n",
        "            if words[0] == \"11\":\n",
        "                etat = 'prevu'\n",
        "                isprevu = True\n",
        "            if words[0] == \"12\":\n",
        "                etat = 'realise'\n",
        "                isrealise = True\n",
        "            if words[0] == \"13\":\n",
        "                if len(words) > 1 and words[1] == \"=\":\n",
        "                    for key in list(tableau_vol.keys()):\n",
        "                        if '_prevu' in key:\n",
        "                            tableau_vol[key.replace('_prevu', '_final')] = tableau_vol[key]\n",
        "                etat = 'final'\n",
        "                isfinal = True\n",
        "            if words[0] == \"14\":\n",
        "                etat = 'transaction'\n",
        "            if words[0] == \"81\":\n",
        "                pass\n",
        "            if words[0] == \"20\":\n",
        "                tableau_vol['callSign_' + etat] = words[1]\n",
        "                tableau_vol['dep_' + etat] = words[2]\n",
        "                tableau_vol['arr_' + etat] = words[3]\n",
        "                tableau_vol['numCautra_' + etat] = words[4]\n",
        "                tableau_vol['dateRelative_' + etat] = words[5]\n",
        "                tableau_vol['typeAvion_' + etat] = words[6]\n",
        "                tableau_vol['work_' + etat] = words[7]\n",
        "                if words[8][:2] == '??':\n",
        "                    pass\n",
        "                else:\n",
        "                    tableau_vol['work1' + etat] = words[8].strip().ljust(9)\n",
        "            if words[0] == \"21\":\n",
        "                tableau_vol['heuresDep_' + etat] = words[1]\n",
        "                tableau_vol['RFL_' + etat] = words[2]\n",
        "                tableau_vol['vitesse_' + etat] = words[3]\n",
        "                tableau_vol['EOBT_' + etat] = words[4]\n",
        "            if words[0] == \"22\":\n",
        "                tableau_vol['regleVol_' + etat] = words[1]\n",
        "                tableau_vol['typeVol_' + etat] = words[2]\n",
        "                tableau_vol['HeurePremiereBaliseActive_' + etat] = words[10]\n",
        "                if words[3][:2] == '??':\n",
        "                    pass\n",
        "                else:\n",
        "                    tableau_vol['IFPL_' + etat] = words[3].strip().ljust(10)\n",
        "                tableau_vol['plnActive_' + etat] = words[4]\n",
        "                tableau_vol['typePlnStan']= words[6]\n",
        "                tableau_vol['plnAnnule_' + etat] = words[5]\n",
        "                if '??' in words[7]:\n",
        "                    pass\n",
        "                elif len(words[7]) == 8:\n",
        "                    date_str = words[7]\n",
        "                    date_obj = datetime.strptime(date_str, '%d%m%Y')\n",
        "                    day_vol = date_obj.timetuple().tm_yday\n",
        "                    tableau_vol['dateBlock_' + etat] = words[7][:4] + words[7][6:]\n",
        "                else:\n",
        "                    tableau_vol['dateBlock_' + etat] = words[7].strip().ljust(6)\n",
        "            if words[0] == \"23\":\n",
        "                if \"??\" in words[4]:\n",
        "                    tableau_vol['adresseModeS_' + etat] = np.NaN\n",
        "                else:\n",
        "                    tableau_vol['adresseModeS_' + etat] = words[4]\n",
        "            if words[0] == \"24\":\n",
        "                tableau_vol['numeroPLNM' + etat] = words[1]\n",
        "                tableau_vol['flightID' + etat] = words[2]\n",
        "            if words[0] == \"31\":\n",
        "                tableau_vol['balise' + etat] = words[1]\n",
        "            if words[0] == \"32\":\n",
        "                tableau_vol['HeurePremiereBalise_' + etat] = words[1]\n",
        "            if words[0] == \"33\":\n",
        "                tableau_vol['listeBalises' + etat] = words[1]\n",
        "            if words[0] == \"36\":\n",
        "                tableau_vol['indicateur' + etat] = words[1]\n",
        "            if words[0] == \"41\":\n",
        "                tableau_vol['carte' + etat] = words[1]\n",
        "            if words[0] == \"71\":\n",
        "                tableau_vol['centreTraversé' + etat] = words[1:]\n",
        "            if words[0] == \"72\":\n",
        "                tableau_vol['listeRangPremier' + etat] = words[1]\n",
        "            if words[0] == \"80\":\n",
        "                tableau_vol['rangTransaction' + etat] = words[1]\n",
        "            if words[0] == \"81\" and not is81:\n",
        "                is81 = True\n",
        "                if len(words) >= 15:\n",
        "                    parts = ligne.split(\"-\")\n",
        "                    last_word = parts[0].split()[-1]\n",
        "                    if \"ABI\" in ligne:\n",
        "                        tableau_vol['typePln'] = \"ABI\"\n",
        "                    if \"(FPL\" in parts[0] or \"(CHG)\" in parts[0]:\n",
        "                        tableau_vol['case7'] = parts[1]\n",
        "                        tableau_vol['case8'] = parts[2]\n",
        "                        tableau_vol['case9'] = parts[3]\n",
        "                        tableau_vol['case10'] = parts[4]\n",
        "                        tableau_vol['case13'] = parts[5]\n",
        "                        tableau_vol['case15'] = parts[6]\n",
        "                        if len(parts) > 8:\n",
        "                            tableau_vol['case16'] = parts[7]\n",
        "                            tableau_vol['case18'] = parts[8]\n",
        "                            if tableau_vol['case18'] == \"RPL\":\n",
        "                                tableau_vol['typePln'] = \"RPL\"\n",
        "                        else:\n",
        "                            #print(ligne)\n",
        "                            compteur += 1\n",
        "                    elif \"(APL\" in parts[0]:\n",
        "                        tableau_vol['case7'] = parts[1]\n",
        "                        tableau_vol['case8'] = parts[2]\n",
        "                        tableau_vol['case9'] = parts[3]\n",
        "                        tableau_vol['case10'] = parts[4]\n",
        "                        tableau_vol['case13'] = parts[5]\n",
        "                        tableau_vol['case15'] = parts[6]\n",
        "                        tableau_vol['typePln'] = \"APL\"\n",
        "                        if len(parts) > 8:\n",
        "                            tableau_vol['case16'] = parts[7]\n",
        "                            tableau_vol['case18'] = parts[-1]\n",
        "                        else:\n",
        "                            compteur += 1\n",
        "            if words[0] == \"82\"and not is82:\n",
        "                is82 = True\n",
        "                tableau_vol['heure'] = (words[1][:2])\n",
        "                tableau_vol['minute'] = (words[1][3:])\n",
        "                tableau_vol['accuseTrt' + etat] = words[1]\n",
        "                if \"CCR:\" in ligne:\n",
        "                    compteurCcr = 0\n",
        "                    for word in words:\n",
        "                        compteurCcr += 1\n",
        "                        if word == \"CCR:\":\n",
        "                            break\n",
        "                    tableau_vol['ccrArrival'] = words[compteurCcr]\n",
        "            if words[0] == \"84\":\n",
        "                tableau_vol['final' + etat] = words[1]\n",
        "\n",
        "    return output\n",
        "\n",
        "def convert_and_calculate(df,date_obj):\n",
        "    df['HeurePremiereBaliseActive_realise'] = df['HeurePremiereBaliseActive_realise'].astype('Int64')\n",
        "    df['HeurePremiereBaliseActive_final'] = df['HeurePremiereBaliseActive_final'].astype('Int64')\n",
        "    df['HeurePremiereBalise_final'] = df['HeurePremiereBalise_final'].astype('Int64')\n",
        "    df['dateRelative_realise'] = df['dateRelative_realise'].astype('Int64')\n",
        "    df['dateRelative_final'] = df['dateRelative_final'].astype('Int64')\n",
        "\n",
        "    def calcul_HeureDeReference(row):\n",
        "        try:\n",
        "            if not pd.isna(row['dateRelative_realise']) and not pd.isnull(row['dateRelative_realise']):\n",
        "                if not pd.isna(row['HeurePremiereBaliseActive_realise']) and int(row['HeurePremiereBaliseActive_realise']) != 0:\n",
        "                    return int(row['HeurePremiereBaliseActive_realise']) + (-1440 if row['dateRelative_realise'] == -1 else 1440 if row['dateRelative_realise'] == 1 else 0)\n",
        "                elif not pd.isna(row['HeurePremiereBalise_final']):\n",
        "                    return int(row['HeurePremiereBalise_final']) + (-1440 if row['dateRelative_realise'] == -1 else 1440 if row['dateRelative_realise'] == 1 else 0)\n",
        "            elif not pd.isna(row['dateRelative_final']):\n",
        "                if not pd.isna(row['HeurePremiereBaliseActive_final']) and int(row['HeurePremiereBaliseActive_final']) != 0:\n",
        "                    return int(row['HeurePremiereBaliseActive_final']) + (-1440 if row['dateRelative_final'] == -1 else 1440 if row['dateRelative_final'] == 1 else 0)\n",
        "                elif not pd.isna(row['HeurePremiereBalise_final']):\n",
        "                    return int(row['HeurePremiereBalise_final']) + (-1440 if row['dateRelative_final'] == -1 else 1440 if row['dateRelative_final'] == 1 else 0)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    df['heure_de_reference'] = df.apply(calcul_HeureDeReference, axis=1)\n",
        "\n",
        "    def calcul_DateDeReference(row):\n",
        "        try:\n",
        "            if not pd.isna(row['dateRelative_realise']) and not pd.isnull(row['dateRelative_realise']):\n",
        "                if row['dateRelative_realise'] == 0:\n",
        "                    return date_obj\n",
        "                elif row['dateRelative_realise'] == 1:\n",
        "                    return date_obj + timedelta(days=1)\n",
        "                elif row['dateRelative_realise'] == -1 and int(row['heure_de_reference'])<0:\n",
        "                    return date_obj - timedelta(days=1)\n",
        "                else:\n",
        "                    return date_obj\n",
        "            elif not pd.isna(row['dateRelative_final']) and not pd.isnull(row['dateRelative_final']):\n",
        "                if row['dateRelative_final'] == 0:\n",
        "                    return date_obj\n",
        "                elif row['dateRelative_final'] == 1:\n",
        "                    return date_obj + timedelta(days=1)\n",
        "                elif row['dateRelative_final'] == -1 and int(row['heure_de_reference'])<0:\n",
        "                    return date_obj - timedelta(days=1)\n",
        "                else:\n",
        "                    return date_obj\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "    df['date_de_reference'] = df.apply(calcul_DateDeReference, axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mbzHg4z_OJ4a"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "def dynamic_analysis(target_date_str):\n",
        "    # Convert the target_date_str to a datetime object\n",
        "    target_date = datetime.strptime(target_date_str, \"%d-%m-%Y\")\n",
        "\n",
        "    # Calculate the previous and next days\n",
        "    previous_day = target_date - timedelta(days=1)\n",
        "\n",
        "    next_day = target_date + timedelta(days=1)\n",
        "\n",
        "\n",
        "    # Format the dates to match the file naming convention\n",
        "    previous_day_str = previous_day.strftime(\"%Y%m%d\")\n",
        "    target_date_str = target_date.strftime(\"%Y%m%d\")\n",
        "    next_day_str = next_day.strftime(\"%Y%m%d\")\n",
        "\n",
        "    # Construct file names\n",
        "    nom_fichier_jour_1 = f'/content/drive/My Drive/data/stan_mars_2024/RDVC-{previous_day_str}.pln'\n",
        "    nom_fichier_jour_2 = f'/content/drive/My Drive/data/stan_mars_2024/RDVC-{target_date_str}.pln'\n",
        "    nom_fichier_jour_3 = f'/content/drive/My Drive/data/stan_mars_2024/RDVC-{next_day_str}.pln'\n",
        "\n",
        "    # Read and process files\n",
        "    fichier_jour_1 = read_and_process_file(nom_fichier_jour_1)\n",
        "    fichier_jour_2 = read_and_process_file(nom_fichier_jour_2)\n",
        "    fichier_jour_3 = read_and_process_file(nom_fichier_jour_3)\n",
        "\n",
        "    # Convert and calculate\n",
        "    date_obj = previous_day\n",
        "    jour_1 = convert_and_calculate(fichier_jour_1,date_obj)\n",
        "\n",
        "    date_obj = target_date\n",
        "    jour_2 = convert_and_calculate(fichier_jour_2,date_obj)\n",
        "\n",
        "    date_obj = next_day\n",
        "    jour_3 = convert_and_calculate(fichier_jour_3,date_obj)\n",
        "\n",
        "\n",
        "    # Return the results\n",
        "    return jour_1, jour_2, jour_3\n",
        "\n",
        "# Example usage\n",
        "dateAnalyse='21-03-2024'\n",
        "jour_1, jour_2, jour_3 = dynamic_analysis(dateAnalyse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBtgOoViwUy-"
      },
      "source": [
        "# Algo 2.3 et 2.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "souikmud3lfh"
      },
      "source": [
        "## Tables utilisées"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "owwuy8ToqbL6"
      },
      "outputs": [],
      "source": [
        "INDICATIF_FICTIF = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"indicatifsfictifs\"), sep=';', skiprows=3)\n",
        "EUROPE_SUD = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"payssud\"), sep=';', skiprows=3)\n",
        "AERONEFS_DE_MOINS_DE_2_TONNES = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"aeronefsmoin2tonnes\"), sep=';', skiprows=3)\n",
        "INDICATEURS_D_EMPLACEMENT_FAUX = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"aerodromesfaux\"), sep=';', skiprows=3)\n",
        "AERODROME_A_VERIFIER = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"aerodromesaverifier\"), sep=';', skiprows=3)\n",
        "AERODROMES_D_APPROCHE = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"aerodromesapproche\"), sep=';', skiprows=3)\n",
        "AERODROMES_FRONTALIERS = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"aerodromesfrontaliers\"), sep=';', skiprows=3)\n",
        "INDICATIF_A_CODE_AUTO = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"indicatifscodesauto\"), sep=';', skiprows=3)\n",
        "INDICATIFS_A_STRUCTURE_TRIGRAMME_CORRECTE = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"structurtrigrammecorrects\"), sep=';', skiprows=3)\n",
        "COMPAGNIES_BIGRAMMES_ET_SUFFIXES = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"cgniebigrammesetsuffixes\"), sep=';', skiprows=3)\n",
        "COMPAGNIES_AVEC_TRIGRAMME = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"compagniesavectrigrammesautorise\"), sep=';', skiprows=3)\n",
        "INDICATIFS_TRIGRAMME_A_VERIFIER = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"structuretrigrammeverif\"), sep=';', skiprows=3)\n",
        "LETTRES_AIR_FRANCE = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"lettresairfrance\"), sep=';', skiprows=3)\n",
        "LETTRES_AIR_FRANCE = LETTRES_AIR_FRANCE[~((LETTRES_AIR_FRANCE['Lettre'].str.contains(\"MODIFIE\", na=False)) & (LETTRES_AIR_FRANCE['Code exo/trait'].isna()) & (LETTRES_AIR_FRANCE['Commentaire'].isna()))]\n",
        "LETTRES_AIR_FRANCE.reset_index(drop=True, inplace=True)\n",
        "IMMATRICULATION_A_VERIFIER = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"immataverif\"), sep=';', skiprows=3)\n",
        "IMMATRICULATION_CORRECTE = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"immatcorrectes\"), sep=';', skiprows=3)\n",
        "OPERATEURS_MILITAIRES = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"oprmili\"), sep=';', skiprows=3)\n",
        "AERONEFS_STRICTEMENT_MILITAIRES = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"aeronefmilitaire\"), sep=';', skiprows=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bYLySOL3lczT"
      },
      "outputs": [],
      "source": [
        "# Fonction pour convertir un modèle en expression régulière\n",
        "def pattern_to_regex(pattern):\n",
        "    # Remplacer # par .*, + par [a-zA-Z] et - par [0-9]\n",
        "    regex = pattern.replace('#', '.?').replace('-', '[0-9]').replace('+', '[a-zA-Z]')\n",
        "    # Ajouter les délimiteurs de début et de fin\n",
        "    regex = '^' + regex + '$'\n",
        "    return regex\n",
        "\n",
        "def trouver_pattern(x, pattern_list):\n",
        "    for pattern in pattern_list:\n",
        "        regex = pattern_to_regex(pattern)\n",
        "        if re.match(regex, x):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def renvoie_pattern(x, pattern_list):\n",
        "    for pattern in pattern_list:\n",
        "        regex = pattern_to_regex(pattern)\n",
        "        if re.match(regex, x):\n",
        "            return pattern\n",
        "    return \"NULL\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ6JIulO0d1M"
      },
      "source": [
        "## Prétraitement utile/inutile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6MP0eh6AotTY"
      },
      "outputs": [],
      "source": [
        "def nbre_centre_francais(list):\n",
        "    rep = 0\n",
        "    for x in list:\n",
        "      if x in ['PARI', 'AIX', 'BRST', 'REIM', 'BORD']:\n",
        "        rep +=1\n",
        "    return rep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sauEz2s_NJcd"
      },
      "outputs": [],
      "source": [
        "def utile_inutile(element):\n",
        "    # Fonction pour trouver une valeur valide dans les colonnes multiples\n",
        "    def get_valid_value(element, columns):\n",
        "        for col in columns:\n",
        "            if col in element and not(element[[col]].isna().iloc[0]):\n",
        "                return element[col]\n",
        "        return None\n",
        "\n",
        "    call_sign_value = get_valid_value(element, [\"callSign_realise\", \"callSign_final\", \"callSign_prevu\"])\n",
        "    PLN_active_value = get_valid_value(element, [\"plnActive_realise\", \"plnActive_final\", \"plnActive_prevu\"])\n",
        "    PLN_annule_value = get_valid_value(element, [\"plnAnnule_realise\", \"plnAnnule_final\", \"plnAnnule_prevu\"])\n",
        "    centre_traverse_value = get_valid_value(element, [\"centreTraversérealise\", \"centreTraverséfinal\", \"centreTraverséprevu\"])\n",
        "    dep_value = get_valid_value(element, [\"dep_realise\", \"dep_final\", \"dep_prevu\"])\n",
        "    arr_value = get_valid_value(element, [\"arr_realise\", \"arr_final\", \"arr_prevu\"])\n",
        "\n",
        "    if trouver_pattern(call_sign_value, INDICATIF_FICTIF[\"Indicatif\"].to_list()):\n",
        "        return \"FICT\"\n",
        "    if PLN_active_value == \"1\":\n",
        "        return \"UTI\"\n",
        "    elif PLN_annule_value == \"1\":\n",
        "        return \"CNL\"\n",
        "    elif nbre_centre_francais(centre_traverse_value) >= 2:\n",
        "        return \"2SLF\"\n",
        "    elif dep_value == arr_value:\n",
        "        return \"CIRC\"\n",
        "    elif dep_value[0] == \"E\" and dep_value in EUROPE_SUD[\"Code pays\"].to_list():\n",
        "        return \"NORD\"\n",
        "    elif (dep_value[0] in EUROPE_SUD[\"Code pays\"].to_list() or dep_value[:2] in EUROPE_SUD) and dep_value[0] == \"E\":\n",
        "        return \"SUD\"\n",
        "    return \"UTI\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "guY2rWKI3vTp"
      },
      "outputs": [],
      "source": [
        "def traitement_utile_inutile(df):\n",
        "    df['utile_inutile'] = df.apply(lambda x: utile_inutile(x), axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WFh0Nc_3yqP8"
      },
      "outputs": [],
      "source": [
        "def test_utile_vol_active_non_fictif():\n",
        "    utilite = result[result[\"callSign_prevu\"]==\"TRA79Y\"][\"utile_inutile\"].iloc[0]\n",
        "    assert utilite == \"UTI\", \"utilité diff de UTI\"\n",
        "\n",
        "def test_inutile_vol_fictif_avec_moins():\n",
        "    utilite = result[result[\"callSign_prevu\"]==\"RFIN65\"][\"utile_inutile\"].iloc[0]\n",
        "    assert utilite == \"FICT\", \"utilité diff de FICT\"\n",
        "\n",
        "def test_inutile_vol_annule():\n",
        "    utilite = result[result[\"callSign_prevu\"]==\"THY90F\"][\"utile_inutile\"].iloc[0]\n",
        "    assert utilite == \"CNL\", \"utilité diff de CNL\"\n",
        "\n",
        "def test_inutile_vol_centrefr():\n",
        "    utilite = result[result[\"callSign_prevu\"]==\"TRA4N\"][\"utile_inutile\"].iloc[0]\n",
        "    assert utilite == \"2SLF\", \"utilité diff de 2SLF\"\n",
        "\n",
        "def test_inutile_vol_circulaire():\n",
        "    utilite = result[result[\"callSign_prevu\"]==\"FNY5118\"][\"utile_inutile\"].iloc[0]\n",
        "    assert utilite == \"CIRC\", \"utilité diff de CIRC\"\n",
        "\n",
        "def test_utile_vol_tout_les_test_faux():\n",
        "    utilite = result[result[\"callSign_prevu\"]==\"TOM22B\"][\"utile_inutile\"].iloc[0]\n",
        "    assert utilite == \"UTI\", \"utilité diff de UTI\"\n",
        "\n",
        "def test_realise_pln_nan():\n",
        "    utilite = result[result[\"callSign_prevu\"]==\"THY90F\"][\"utile_inutile\"].iloc[0]\n",
        "    assert utilite == \"CNL\", \"utilité diff de CNL\"\n",
        "\n",
        "def test_realise_centre_nan():\n",
        "    utilite = result[result[\"callSign_prevu\"]==\"UAL71\"][\"utile_inutile\"].iloc[0]\n",
        "    assert utilite == \"2SLF\", \"utilité diff de 2SLF\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMJOsBiX0lEx"
      },
      "source": [
        "## Traitement unitaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKZEI6Yh0qHa"
      },
      "source": [
        "## Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8cymE4Up6eTv"
      },
      "outputs": [],
      "source": [
        "def TU_init(df_utile):\n",
        "    df_utile['aeronef_de_moins_de_deux_tonnes'] = False\n",
        "    df_utile['vol_a_transmettre'] = False\n",
        "    df_utile['vol_approche'] = False\n",
        "    df_utile['vol_interieur'] = False\n",
        "    df_utile['vol_frontalier'] = False\n",
        "    df_utile['vol_VFR'] = False\n",
        "    df_utile[\"code_d_exoneration\"] = 'Z'\n",
        "    df_utile['code_exploitant'] = 'Z'\n",
        "    df_utile['compagnie_française'] = False\n",
        "    df_utile['type_d_avion_militaire'] = False\n",
        "    df_utile['PLN_à_verifier_TU'] = False\n",
        "    df_utile['PLN_valide'] = True\n",
        "    df_utile['RAZ_des_invalidites_de_type_TU'] = False\n",
        "    df_utile['invalidite_TU'] = [[] for _ in range(len(df_utile))]\n",
        "    df_utile['type_d_indicatif'] = \"\"\n",
        "    return df_utile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWu-l9Uv0s81"
      },
      "source": [
        "## Algo 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zHa3edsNL9ro"
      },
      "outputs": [],
      "source": [
        "def TU_1(df_utile):\n",
        "    def TU_1_element(x):\n",
        "        # Vérification de PLN_active\n",
        "        for col in [\"plnActive_realise\", \"plnActive_final\", \"plnActive_prevu\"]:\n",
        "            if col in x and not pd.isna(x[col]):\n",
        "                if x[col] == \"0\":\n",
        "                    x['invalidite_TU'] = x.get('invalidite_TU', []) + [\"NACT\"]\n",
        "                break\n",
        "\n",
        "        # Vérification de typeavion\n",
        "        for col in [\"typeAvion_realise\", \"typeAvion_final\", \"typeAvion_prevu\"]:\n",
        "            if col in x and not pd.isna(x[col]):\n",
        "                if x[col] == \"ZZZZ\":\n",
        "                    x['invalidite_TU'] = x.get('invalidite_TU', []) + [\"TYPAV\"]\n",
        "                    x['PLN_valide'] = False\n",
        "                if x[col] in AERONEFS_DE_MOINS_DE_2_TONNES[\"Type avion\"].to_list():\n",
        "                    x['aeronef_de_moins_de_deux_tonnes'] = True\n",
        "                break\n",
        "        return x\n",
        "    df_utile = df_utile.apply(TU_1_element, axis=1)\n",
        "    return df_utile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1lsd0MV0_KF"
      },
      "source": [
        "## Algo 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uZzbvUjzzF40"
      },
      "outputs": [],
      "source": [
        "# def TU_2(df_utile):\n",
        "#     def TU_2_element(x):\n",
        "#         if len(x['depfinal']) != 4:\n",
        "#             x['invalidite_TU'].append(\"DEPAR1\")\n",
        "#             x['PLN_valide'] = False\n",
        "#         elif x['depfinal'] in INDICATEURS_D_EMPLACEMENT_FAUX:\n",
        "#             x['invalidite_TU'].append(\"DEPAR2\")\n",
        "#             x['PLN_valide'] = False\n",
        "#         elif trouver_pattern(x['depfinal'], AERODROME_A_VERIFIER):\n",
        "#             x['invalidite_TU'].append(\"DVPAR3\")\n",
        "#             x['PLN_valide'] = False\n",
        "#         if len(x['arrfinal']) != 4:\n",
        "#             x['invalidite_TU'].append(\"ARRIV1\")\n",
        "#             x['PLN_valide'] = False\n",
        "#         elif x['arrfinal'] in INDICATEURS_D_EMPLACEMENT_FAUX:\n",
        "#             x['invalidite_TU'].append(\"ARRIV2\")\n",
        "#             x['PLN_valide'] = False\n",
        "#         elif trouver_pattern(x['arrfinal'], AERODROME_A_VERIFIER):\n",
        "#             x['invalidite_TU'].append(\"AVRIV3\")\n",
        "#             x['PLN_valide'] = False\n",
        "#     df_utile = df_utile.apply(TU_2_element, axis=1)\n",
        "#     return df_utile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uyD7iQL5MvmE"
      },
      "outputs": [],
      "source": [
        "def TU_2(df_utile):\n",
        "    def TU_2_element(x):\n",
        "        # Vérification des colonnes de départ\n",
        "        for col in [\"dep_realise\", \"dep_final\", \"dep_prevu\"]:\n",
        "            if col in x and not pd.isna(x[col]):\n",
        "                if len(x[col]) != 4:\n",
        "                    x['invalidite_TU'].append(\"DEPAR1\")\n",
        "                    x['PLN_valide'] = False\n",
        "                elif trouver_pattern(x[col], INDICATEURS_D_EMPLACEMENT_FAUX[\"Code terrain\"]):\n",
        "                    x['invalidite_TU'].append(\"DEPAR2\")\n",
        "                    x['PLN_valide'] = False\n",
        "                elif trouver_pattern(x[col], AERODROME_A_VERIFIER[\"Code terrain\"]):\n",
        "                    x['invalidite_TU'].append(\"DVPAR3\")\n",
        "                    x['PLN_valide'] = False\n",
        "            break\n",
        "\n",
        "        # Vérification des colonnes d'arrivée\n",
        "        for col in [\"arr_realise\", \"arr_final\", \"arr_prevu\"]:\n",
        "            if col in x and not pd.isna(x[col]):\n",
        "                if len(x[col]) != 4:\n",
        "                    x['invalidite_TU'].append(\"ARRIV1\")\n",
        "                    x['PLN_valide'] = False\n",
        "                elif trouver_pattern(x[col], INDICATEURS_D_EMPLACEMENT_FAUX[\"Code terrain\"]):\n",
        "                    x['invalidite_TU'].append(\"ARRIV2\")\n",
        "                    x['PLN_valide'] = False\n",
        "                elif trouver_pattern(x[col], AERODROME_A_VERIFIER[\"Code terrain\"]):\n",
        "                    x['invalidite_TU'].append(\"AVRIV3\")\n",
        "                    x['PLN_valide'] = False\n",
        "            break\n",
        "        return x\n",
        "    df_utile = df_utile.apply(TU_2_element, axis=1)\n",
        "    return df_utile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp6OEDts9al4"
      },
      "source": [
        "## Algo 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HeBP1td7vOeW"
      },
      "outputs": [],
      "source": [
        "def TU_3_bis(df_utile):\n",
        "    eurocontrol = ['EB','ED','EF','EG','EH','EI','EK','EL','EN','EP','ES','EV','EY','LA','LB','LC','LD','LE','LG','LH','LI','LJ','LK','LM','LO','LP','LQ','LR','LS','LT','LU','LW','LY','LZ','UD','UG','GC']\n",
        "    def TU_3_bis_element(x):\n",
        "        dep_value = None\n",
        "        for col in [\"dep_realise\", \"dep_final\", \"dep_prevu\"]:\n",
        "            if col in x and not pd.isna(x[col]) and x[col] != \"\":\n",
        "                dep_value = x[col]\n",
        "                break\n",
        "        if dep_value == \"ZZZZ\":\n",
        "            x['PLN_valide'] = False\n",
        "            x['PLN_à_verifier_TU'] = False\n",
        "            x['invalidite_TU'].extend([\"DEPAR2\", \"TRANS1\"])\n",
        "        elif dep_value[:2] in eurocontrol:\n",
        "            x['vol_a_transmettre'] = False\n",
        "        elif x[\"ccrArrival\"] == \"ALGR\":\n",
        "            x['vol_a_transmettre'] = True\n",
        "        elif x[\"ccrArrival\"] == \"ETRG\":\n",
        "            if ((x['dep_prevu'][:1]=='D' or x['dep_prevu'][:1]=='F') and 'TABOT' in x['case15']):\n",
        "                x['vol_a_transmettre'] = True\n",
        "        else:\n",
        "            x['vol_a_transmettre'] = False\n",
        "        return x\n",
        "\n",
        "    df_utile = df_utile.apply(TU_3_bis_element, axis=1)\n",
        "    return df_utile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tGEEOGZj9cy_"
      },
      "outputs": [],
      "source": [
        "# def TU_3(df_utile):\n",
        "#     def TU_3_element(x):\n",
        "#         if x[\"depfinal\"] == \"ZZZZ\":\n",
        "#             x['PLN_valide'] = False\n",
        "#             x['PLN_à_verifier_TU'] = False\n",
        "#             x['invalidite_TU'].append(\"DEPAR2\")\n",
        "#             x['invalidite_TU'].append(\"TRANS1\")\n",
        "#         else:\n",
        "#             if x[\"depfinal\"][:2] in liste_origin_vol | x[\"depfinal\"][:2] in liste_origin_vol:\n",
        "#                 if trouver_code(x[\"depfinal\"], liste_origin_vol) == \"A\":\n",
        "#                     x['vol_a_transmettre'] = False\n",
        "#                 elif trouver_code(x[\"depfinal\"], liste_origin_vol) == \"B\":\n",
        "#                     x['vol_a_transmettre'] = True\n",
        "#                 elif trouver_code(x[\"depfinal\"], liste_origin_vol) == \"C\":\n",
        "#                     if x[\"AVR\"] == 1:\n",
        "#                         x['vol_a_transmettre'] = \"ADET\"\n",
        "#                         x[\"PLN_valide\"] = False\n",
        "#                         x['invalidite_TU'].append(\"TRANSC\")\n",
        "#                     else:\n",
        "#                         x['vol_a_transmettre'] = False\n",
        "#                 elif trouver_code(x[\"depfinal\"], liste_origin_vol) == \"D\":\n",
        "#                     x['vol_a_transmettre'] = \"ADET\"\n",
        "#                     x[\"PLN_valide\"] = False\n",
        "#                     x['invalidite_TU'].append(\"TRANSD\")\n",
        "#                 elif trouver_code(x[\"depfinal\"], liste_origin_vol) == \"E\":\n",
        "#                     if x[\"SVR\"] == 1:\n",
        "#                         x['vol_a_transmettre'] = False\n",
        "#                     else:\n",
        "#                         x['vol_a_transmettre'] = \"ADET\"\n",
        "#                         x[\"PLN_valide\"] = False\n",
        "#                         x['invalidite_TU'].append(\"TRANSE\")\n",
        "#                 else:\n",
        "#                     x['vol_a_transmettre'] = \"ADET\"\n",
        "#                     x[\"PLN_valide\"] = False\n",
        "#                     x['invalidite_TU'].append(\"TRANSI\")\n",
        "#             else:\n",
        "#                 if x[\"AVR\"] == 1:\n",
        "#                     x['vol_a_transmettre'] = True\n",
        "#                 else:\n",
        "#                     if x[\"balisefinal\"] == \"PTGEO\":\n",
        "#                         x['vol_a_transmettre'] = \"ADET\"\n",
        "#                         x[\"PLN_valide\"] = False\n",
        "#                         x['invalidite_TU'].append(\"TRANSP\")\n",
        "#                     else:\n",
        "#                         x['vol_a_transmettre'] = False\n",
        "#     df_utile = df_utile.apply(TU_3_element, axis=1)\n",
        "#     return df_utile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EM1vCq2ZOGK2"
      },
      "outputs": [],
      "source": [
        "# def TU_3(df_utile):\n",
        "#     def TU_3_element(x):\n",
        "#         dep_value = None\n",
        "#         balise_value = None\n",
        "\n",
        "#         # Vérification des colonnes de départ\n",
        "#         for col in [\"deprealise\", \"depfinal\", \"depprevu\"]:\n",
        "#             if col in x and not pd.isna(x[col]) and x[col] != \"\":\n",
        "#                 dep_value = x[col]\n",
        "#                 break\n",
        "#         for col in [\"baliserealise\", \"balisefinal\", \"baliseprevu\"]:\n",
        "#             if col in x and not pd.isna(x[col]) and x[col] != \"\":\n",
        "#                 balise_value = x[col]\n",
        "#                 break\n",
        "\n",
        "#         if dep_value == \"ZZZZ\":\n",
        "#             x['PLN_valide'] = False\n",
        "#             x['PLN_à_verifier_TU'] = False\n",
        "#             x['invalidite_TU'].extend([\"DEPAR2\", \"TRANS1\"])\n",
        "#         elif dep_value:\n",
        "#             dep_code = trouver_code(dep_value, liste_origin_vol)\n",
        "#             if dep_code == \"A\":\n",
        "#                 x['vol_a_transmettre'] = False\n",
        "#             elif dep_code == \"B\":\n",
        "#                 x['vol_a_transmettre'] = True\n",
        "#             elif dep_code == \"C\":\n",
        "#                 if x[\"AVR\"] == 1:\n",
        "#                     x['vol_a_transmettre'] = \"ADET\"\n",
        "#                     x[\"PLN_valide\"] = False\n",
        "#                     x['invalidite_TU'].append(\"TRANSC\")\n",
        "#                 else:\n",
        "#                     x['vol_a_transmettre'] = False\n",
        "#             elif dep_code == \"D\":\n",
        "#                 x['vol_a_transmettre'] = \"ADET\"\n",
        "#                 x[\"PLN_valide\"] = False\n",
        "#                 x['invalidite_TU'].append(\"TRANSD\")\n",
        "#             elif dep_code == \"E\":\n",
        "#                 if x[\"SVR\"] == 1:\n",
        "#                     x['vol_a_transmettre'] = False\n",
        "#                 else:\n",
        "#                     x['vol_a_transmettre'] = \"ADET\"\n",
        "#                     x[\"PLN_valide\"] = False\n",
        "#                     x['invalidite_TU'].append(\"TRANSE\")\n",
        "#             else:\n",
        "#                 x['vol_a_transmettre'] = \"ADET\"\n",
        "#                 x[\"PLN_valide\"] = False\n",
        "#                 x['invalidite_TU'].append(\"TRANSI\")\n",
        "#         else:\n",
        "#             if x[\"AVR\"] == 1:\n",
        "#                 x['vol_a_transmettre'] = True\n",
        "#             else:\n",
        "#                 if balise_value == \"PTGEO\":\n",
        "#                     x['vol_a_transmettre'] = \"ADET\"\n",
        "#                     x[\"PLN_valide\"] = False\n",
        "#                     x['invalidite_TU'].append(\"TRANSP\")\n",
        "#                 else:\n",
        "#                     x['vol_a_transmettre'] = False\n",
        "\n",
        "#         return x\n",
        "\n",
        "#     df_utile = df_utile.apply(TU_3_element, axis=1)\n",
        "#     return df_utile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzq_RqwG3Gc8"
      },
      "source": [
        "##  Algo 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4vjBaC-9Ow5N"
      },
      "outputs": [],
      "source": [
        "def TU_4(df_utile):\n",
        "    def TU_4_element(x):\n",
        "        x['vol_a_transmettre'] = True\n",
        "        for col in [\"dep_realise\", \"dep_final\", \"dep_prevu\"]:\n",
        "            if col in x and not pd.isna(x[col]) and x[col] != \"\":\n",
        "                dep_value = x[col]\n",
        "                break\n",
        "        for col in [\"arr_realise\", \"arr_final\", \"arr_prevu\"]:\n",
        "            if col in x and not pd.isna(x[col]) and x[col] != \"\":\n",
        "                arr_value = x[col]\n",
        "                break\n",
        "        for col in [\"plnActive_realise\", \"plnActive_final\", \"plnActive_prevu\"]:\n",
        "            if col in x and not pd.isna(x[col]) and x[col] != \"\":\n",
        "                plnActive = x[col]\n",
        "                break\n",
        "\n",
        "        if dep_value in AERODROMES_D_APPROCHE[\"Code terrain\"].to_list():\n",
        "            x[\"vol_approche\"] = True\n",
        "\n",
        "        if arr_value[:2] == \"LF\":\n",
        "            x[\"vol_interieur\"] = True\n",
        "\n",
        "        elif  plnActive == 0 and dep_value in AERODROMES_FRONTALIERS[\"Code terrain\"].to_list():\n",
        "            x[\"vol_frontalier\"] = True\n",
        "\n",
        "        return x\n",
        "    df_utile = df_utile.apply(TU_4_element, axis=1)\n",
        "    return df_utile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g11_6RQE3I3G"
      },
      "outputs": [],
      "source": [
        "# def TU_4(df_utile):\n",
        "#     def TU_4_element(x):\n",
        "#         x['vol_a_transmettre'] = True\n",
        "#         if x[\"depfinal\"] in AERODROMES_D_APPROCHE:\n",
        "#             x[\"vol_approche\"] = True\n",
        "#         if x[\"arrfinal\"][:2] == \"LF\":\n",
        "#             x[\"vol_interieur\"] == True\n",
        "#         elif x[\"PLN_activefinal\"] != 1 & x[\"depfinal\"] in AERODROMES_FRONTALIERS:\n",
        "#             x[\"vol_frontalier\"] == True\n",
        "#     df_utile = df_utile.apply(TU_4_element, axis=1)\n",
        "#     return df_utile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNkVxDq9MWoH"
      },
      "source": [
        "## Algo 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yjEqlYxDhXGd"
      },
      "outputs": [],
      "source": [
        "def TU_5(df_utile):\n",
        "    def TU_5_element(x):\n",
        "        # Vérification des colonnes balise et regleVol\n",
        "        balise_value = None\n",
        "        regleVol_value = None\n",
        "        dep_value = None\n",
        "        for col in [\"baliserealise\", \"balisefinal\", \"baliseprevu\"]:\n",
        "            if col in x and not pd.isna(x[col]) and x[col] != \"\":\n",
        "                balise_value = x[col]\n",
        "                break\n",
        "        for col in [\"regleVol_realise\", \"regleVol_final\", \"regleVol_prevu\"]:\n",
        "            if col in x and not pd.isna(x[col]) and x[col] != \"\":\n",
        "                regleVol_value = x[col]\n",
        "                break\n",
        "        for col in [\"dep_realise\", \"dep_final\", \"dep_prevu\"]:\n",
        "            if col in x and not pd.isna(x[col]) and x[col] != \"\":\n",
        "                dep_value = x[col]\n",
        "                break\n",
        "        # Conditions basées sur les valeurs trouvées\n",
        "        if x[\"typePln\"] == \"VFR\" and balise_value.startswith('VFR') and regleVol_value == \"V\":\n",
        "            x['vol_a_transmettre'] = False\n",
        "        elif x[\"typePln\"] in [\"APL\", \"FPL\", \"FIH\", \"FII\"] and balise_value.startswith('VFR'):\n",
        "            x['vol_a_transmettre'] = False\n",
        "            x['vol_VFR'] = True\n",
        "            x[\"typePln\"] = \"VFR\"\n",
        "        else:\n",
        "            if not x.get('vol_VFR', False) and regleVol_value == \"V\" and x.get('vol_a_transmettre', True):\n",
        "                x[\"PLN_valide\"] = False\n",
        "                x['invalidite_TU'].append(\"TRANS0\")\n",
        "            elif dep_value and dep_value[:2] != \"LF\" and not x.get('vol_a_transmettre', True) and regleVol_value == \"Z\":\n",
        "                x[\"PLN_valide\"] = False\n",
        "                x['invalidite_TU'].append(\"TRANS2\")\n",
        "                x[\"typePln\"] = \"AFI\"\n",
        "            if not x.get('vol_VFR', False) and any(s.startswith('TRANS') for s in x['invalidite_TU']):\n",
        "                x['vol_a_transmettre'] = \"ADET\"\n",
        "        if x[\"typePln\"] in [\"APL\", \"FPL\"] and regleVol_value in [\"Y\", \"Z\"] and x.get('vol_a_transmettre', True):\n",
        "            x[\"code_d_exoneration\"] = \"Y\"\n",
        "        return x\n",
        "    df_utile = df_utile.apply(TU_5_element, axis=1)\n",
        "    return df_utile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lgsM6LBDMVaR"
      },
      "outputs": [],
      "source": [
        "# def TU_5(df_utile):\n",
        "#     def TU_5_element(x):\n",
        "#         if x[\"typePln\"] == \"VFR\" and x[\"baliseprevu\"].str.startswith('VFR') and x[\"regleVol_prevu\"] == \"V\":\n",
        "#             x['vol_a_transmettre'] = False\n",
        "#         elif (x[\"typePln\"] == \"APL\" or x[\"typePln\"] == \"FPL\" or x[\"typePln\"] == \"FIH\" or x[\"typePln\"] == \"FII\") and x[\"baliseprevu\"].str.startswith('VFR'):\n",
        "#             x['vol_a_transmettre'] = False\n",
        "#             x['vol_VFR'] = True\n",
        "#             x[\"typePln\"] = \"VFR\"\n",
        "#         else:\n",
        "#             if x['vol_VFR'] == False and x[\"regleVol_prevu\"] == \"V\" and x['vol_a_transmettre'] == True:\n",
        "#                 x[\"PLN_valide\"] == False\n",
        "#                 x['invalidite_TU'].append(\"TRANS0\")\n",
        "#             elif x[\"depprevu\"][:2] != \"LF\" and x['vol_a_transmettre'] == False and x[\"regleVol_prevu\"] == \"Z\":\n",
        "#                 x[\"PLN_valide\"] == False\n",
        "#                 x['invalidite_TU'].append(\"TRANS2\")\n",
        "#                 x[\"typePln\"] = \"AFI\"\n",
        "#             if x['vol_VFR'] == False and any(s.startswith('TRANS') for s in x['invalidite_TU']):\n",
        "#                 x['vol_a_transmettre'] = \"ADET\"\n",
        "#         if (x[\"typePln\"] == \"APL\" or x[\"typePln\"] == \"FPL\") and ( x[\"regleVol_prevu\"] == \"Y\" or  x[\"regleVol_prevu\"] == \"Z\") and x['vol_a_transmettre'] == True:\n",
        "#             x[\"code_d_exoneration\"] = \"Y\"\n",
        "#     df_utile = df_utile.apply(TU_5_element, axis=1)\n",
        "#     return df_utile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kneVqL1chDCJ"
      },
      "source": [
        "## Algo 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uLCqY5gU0JHk"
      },
      "outputs": [],
      "source": [
        "def TU_65_element(x):\n",
        "    # Fonction pour trouver une valeur valide dans les colonnes multiples\n",
        "    def get_valid_value(element, columns):\n",
        "        for col in columns:\n",
        "            if col in element and not pd.isna(element[col]) and element[col] != \"\":\n",
        "                return element[col]\n",
        "        return None\n",
        "    type_avion_value = get_valid_value(x, [\"typeAvion_realise\", \"typeAvion_final\", \"typeAvion_prevu\"])\n",
        "    if type_avion_value in AERONEFS_STRICTEMENT_MILITAIRES['Type avion'].tolist():\n",
        "        x['type_d_avion_militaire'] = True\n",
        "        x['PLN_valide'] = False\n",
        "        x['invalidite_TU'].extend([\"TYPA19\", \"INDI19\"])\n",
        "        filtre_avion = AERONEFS_STRICTEMENT_MILITAIRES[AERONEFS_STRICTEMENT_MILITAIRES[\"Type avion\"] == type_avion_value]\n",
        "        if not pd.isna(filtre_avion[\"Code exoneration\"].iloc[0]):\n",
        "            x[\"code_d_exoneration\"] = filtre_avion[\"Code exoneration\"].iloc[0]\n",
        "            x['code_exploitant'] = filtre_avion[\"Code exploitant\"].iloc[0]\n",
        "        else:\n",
        "            x['code_exploitant'] = 'Z'\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "K1_LKnnNv91X"
      },
      "outputs": [],
      "source": [
        "def TU_64_element(x):\n",
        "    # Fonction pour trouver une valeur valide dans les colonnes multiples\n",
        "    def get_valid_value(element, columns):\n",
        "        for col in columns:\n",
        "            if col in element and not pd.isna(element[col]) and element[col] != \"\":\n",
        "                return element[col]\n",
        "        return None\n",
        "    type_avion_value = get_valid_value(x, [\"typeAvion_realise\", \"typeAvion_final\", \"typeAvion_prevu\"])\n",
        "    OPR = None\n",
        "    if not(pd.isna(x[\"case18\"])):\n",
        "        OPR = trouver_case18(\"OPR/\", x[\"case18\"])\n",
        "    if not(pd.isna(x[\"case18\"])) and OPR != \"NULL\" and OPR in OPERATEURS_MILITAIRES['Nom operateur'].tolist():\n",
        "        operateur_militaire = OPERATEURS_MILITAIRES[OPERATEURS_MILITAIRES[\"Nom operateur\"] == OPR]\n",
        "        x[\"code_d_exoneration\"] = operateur_militaire[\"Code exoneration\"].iloc[0]\n",
        "        x['code_exploitant'] = operateur_militaire[\"Code exploitant\"].iloc[0]\n",
        "    else:\n",
        "        if type_avion_value in AERONEFS_STRICTEMENT_MILITAIRES['Type avion'].tolist():\n",
        "            x['type_d_avion_militaire'] = True\n",
        "            avion_militaire = AERONEFS_STRICTEMENT_MILITAIRES[AERONEFS_STRICTEMENT_MILITAIRES[\"Type avion\"] == type_avion_value]\n",
        "            if not pd.isna(avion_militaire[\"Code exoneration\"].iloc[0]):\n",
        "                x[\"code_d_exoneration\"] = avion_militaire[\"Code exoneration\"].iloc[0]\n",
        "                x['code_exploitant'] = avion_militaire[\"Code exploitant\"].iloc[0]\n",
        "            else:\n",
        "                x['code_exploitant'] = 'Z'\n",
        "        x['PLN_valide'] = False\n",
        "        x['invalidite_TU'].extend([\"EXO19\", \"INDI19\", \"OPR19\"])\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CobnuDp9t8Zh"
      },
      "outputs": [],
      "source": [
        "def TU_63_element(x):\n",
        "    # Fonction pour trouver une valeur valide dans les colonnes multiples\n",
        "    def get_valid_value(element, columns):\n",
        "        for col in columns:\n",
        "            if col in element and not pd.isna(element[col]) and element[col] != \"\":\n",
        "                return element[col]\n",
        "        return None\n",
        "    call_sign_value = get_valid_value(x, [\"callSign_realise\", \"callSign_final\", \"callSign_prevu\"])\n",
        "    if call_sign_value and trouver_pattern(call_sign_value, IMMATRICULATION_CORRECTE[\"Immatriculation\"]):\n",
        "        if trouver_pattern(call_sign_value, IMMATRICULATION_A_VERIFIER[\"Immatriculation\"]):\n",
        "            x['PLN_valide'] = False\n",
        "            x['invalidite_TU'].extend([\"IVDIC$\", \"EXO$\", \"OPR$\"])\n",
        "        else:\n",
        "            x['type_d_indicatif'] = \"IM\"\n",
        "        x = TU_65_element(x)\n",
        "    else:\n",
        "        x = TU_64_element(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WepgiodZrkDM"
      },
      "outputs": [],
      "source": [
        "def TU_62_element(x):\n",
        "    def get_valid_value(element, columns):\n",
        "        for col in columns:\n",
        "            if col in element and not pd.isna(element[col]) and element[col] != \"\":\n",
        "                return element[col]\n",
        "        return None\n",
        "    call_sign_value = get_valid_value(x, [\"callSign_realise\", \"callSign_final\", \"callSign_prevu\"])\n",
        "    if call_sign_value and call_sign_value[:2] in COMPAGNIES_BIGRAMMES_ET_SUFFIXES[\"Indicatif\"].values:\n",
        "        x['code_exploitant'] = COMPAGNIES_BIGRAMMES_ET_SUFFIXES[COMPAGNIES_BIGRAMMES_ET_SUFFIXES[\"Indicatif\"] == call_sign_value[:2]][\"Code exploitant\"].iloc[0]\n",
        "        if x['vol_interieur'] == True:\n",
        "            x[\"code_d_exoneration\"] = COMPAGNIES_BIGRAMMES_ET_SUFFIXES[COMPAGNIES_BIGRAMMES_ET_SUFFIXES[\"Indicatif\"] == call_sign_value[:2]][\"Code exoneration\"].iloc[0]\n",
        "            x['compagnie_française'] = True\n",
        "            x['type_d_indicatif'] = \"BI\"\n",
        "        else:\n",
        "            x['PLN_valide'] = False\n",
        "            x['invalidite_TU'].extend([\"INDIC%\", \"EXO%\", \"OPR%\"])\n",
        "        x = TU_65_element(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "patFBS-for_O"
      },
      "outputs": [],
      "source": [
        "def TU_612_element(x):\n",
        "    def get_valid_value(element, columns):\n",
        "        for col in columns:\n",
        "            if col in element and not pd.isna(element[col]) and element[col] != \"\":\n",
        "                return element[col]\n",
        "        return None\n",
        "\n",
        "    call_sign_value = get_valid_value(x, [\"callSign_realise\", \"callSign_final\", \"callSign_prevu\"])\n",
        "\n",
        "    if call_sign_value and re.search(r'\\d[A-Z]$', call_sign_value) and call_sign_value[-1] == -1:\n",
        "        x['PLN_valide'] = False\n",
        "        x['invalidite_TU'].append(\"INDIC6\")\n",
        "    x = TU_65_element(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mSjSmmTwmSzE"
      },
      "outputs": [],
      "source": [
        "def TU_611_element(x):\n",
        "    def get_valid_value(element, columns):\n",
        "        for col in columns:\n",
        "            if col in element and not pd.isna(element[col]) and element[col] != \"\":\n",
        "                return element[col]\n",
        "        return None\n",
        "    call_sign_value = get_valid_value(x, [\"callSign_realise\", \"callSign_final\", \"callSign_prevu\"])\n",
        "    if call_sign_value and call_sign_value[-1] in LETTRES_AIR_FRANCE['Lettre'].tolist():\n",
        "        code_air_france = LETTRES_AIR_FRANCE[LETTRES_AIR_FRANCE['Lettre'] == call_sign_value[-1]][\"Code exo/trait\"].iloc[0]\n",
        "        if code_air_france == 2:\n",
        "            x['PLN_valide'] = False\n",
        "            x['invalidite_TU'].extend([\"INDIC8\", \"EXO8\"])\n",
        "        elif not code_air_france.isdigit():\n",
        "            x[\"code_d_exoneration\"] = code_air_france\n",
        "    else:\n",
        "        x['PLN_valide'] = False\n",
        "        x['invalidite_TU'].append(\"EXO10\")\n",
        "    x = TU_65_element(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "sFkMTVTeUn77"
      },
      "outputs": [],
      "source": [
        "def TU_61_element(x):\n",
        "    def get_valid_value(element, columns):\n",
        "        for col in columns:\n",
        "            if col in element and not pd.isna(element[col]) and element[col] != \"\":\n",
        "                return element[col]\n",
        "        return None\n",
        "    call_sign_value = get_valid_value(x, [\"callSign_realise\", \"callSign_final\", \"callSign_prevu\"])\n",
        "    if call_sign_value[:3] in COMPAGNIES_AVEC_TRIGRAMME[\"Trigramme\"].tolist():\n",
        "        x['type_d_indicatif'] = \"TR\"\n",
        "        if trouver_pattern(call_sign_value, INDICATIFS_TRIGRAMME_A_VERIFIER[\"Indicatif\"]):\n",
        "            x['PLN_valide'] = False\n",
        "            x['invalidite_TU'].extend([\"IVDIC5\", \"EXO5\"])\n",
        "        elif call_sign_value[:3] == \"AFR\":\n",
        "            x['compagnie_française'] = True\n",
        "            if re.search(r'\\d[A-Z]$', call_sign_value):\n",
        "                x = TU_611_element(x)\n",
        "            else:\n",
        "                x = TU_65_element(x)\n",
        "        else:\n",
        "            x = TU_612_element(x)\n",
        "    else:\n",
        "        x = TU_64_element(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-3qWvJoahF70"
      },
      "outputs": [],
      "source": [
        "def TU_6(df_utile):\n",
        "    def TU_6_element(x):\n",
        "        def get_valid_value(element, columns):\n",
        "            for col in columns:\n",
        "                if col in element and not pd.isna(element[col]) and element[col] != \"\":\n",
        "                    return element[col]\n",
        "            return None\n",
        "        call_sign_value = get_valid_value(x, [\"callSign_realise\", \"callSign_final\", \"callSign_prevu\"])\n",
        "        if call_sign_value and trouver_pattern(call_sign_value, INDICATIF_A_CODE_AUTO[\"Indicatif\"].tolist()):\n",
        "            Indicatif = renvoie_pattern(call_sign_value, INDICATIF_A_CODE_AUTO[\"Indicatif\"].tolist())\n",
        "            x[\"code_d_exoneration\"] = INDICATIF_A_CODE_AUTO[INDICATIF_A_CODE_AUTO[\"Indicatif\"] == Indicatif][\"Code exoneration\"].iloc[0]\n",
        "            x['code_exploitant'] = INDICATIF_A_CODE_AUTO[INDICATIF_A_CODE_AUTO[\"Indicatif\"] == Indicatif][\"Code exploitant\"].iloc[0]\n",
        "            if x[\"code_d_exoneration\"] in [\"X\", \"M\"]:\n",
        "                x['type_d_avion_militaire'] = True\n",
        "        else:\n",
        "            if trouver_pattern(call_sign_value, INDICATIFS_A_STRUCTURE_TRIGRAMME_CORRECTE[\"Indicatif\"].tolist()):\n",
        "                x = TU_61_element(x)\n",
        "            elif re.match(r'^[A-Z]{2}\\d{3}[A-Z]{2}$', call_sign_value) and call_sign_value[:2] in COMPAGNIES_BIGRAMMES_ET_SUFFIXES[\"Bigramme\"].tolist():\n",
        "                x = TU_62_element(x)\n",
        "            else:\n",
        "                x = TU_63_element(x)\n",
        "        return x\n",
        "    df_utile = df_utile.apply(TU_6_element, axis=1)\n",
        "    return df_utile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SP9zvis0shL"
      },
      "source": [
        "## Algo 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "h8r8UAOagKoz"
      },
      "outputs": [],
      "source": [
        "# Chaîne d'entrée\n",
        "def trouver_case18(prefix, input_string):\n",
        "    index_find = input_string.find(prefix)\n",
        "    if index_find == -1:\n",
        "        return \"NULL\"\n",
        "    else:\n",
        "        start_index = index_find + len(prefix)\n",
        "        end_index = input_string.find(' ', start_index)\n",
        "        opr_code = input_string[start_index:end_index]\n",
        "        return opr_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "sKyWsrhp0ugv"
      },
      "outputs": [],
      "source": [
        "# def TU_7(df_utile):\n",
        "#     def TU_7_element(x):\n",
        "#         if x[\"PLN_activeprevu\"] == \"0\" and x['vol_a_transmettre'] == True:\n",
        "#             x['PLN_valide'] = False\n",
        "#         if x[\"callSign_prevu\"] == \"APL\" or x[\"callSign_prevu\"] == \"FPL\":\n",
        "#             if x['vol_a_transmettre'] == True:\n",
        "#                 if x[\"code_d_exoneration\"] == \"Y\" or [\"code_d_exoneration\"] == \"Z\":\n",
        "#                     if x['typeVol_prevu'] == \"M\":\n",
        "#                         x['PLN_valide'] = False\n",
        "#                         x['invalidite_TU'].append(\"EXO10\")\n",
        "#                         x['invalidite_TU'].append(\"OPR10\")\n",
        "#                     else:\n",
        "#                         if trouver_case18(\"RMK/\", x[\"case18\"]) == \"TRAINING\" and x['vol_interieur'] == True:\n",
        "#                             x[\"code_d_exoneration\"] = \"T\"\n",
        "#                         elif x['typeVol_prevu'] == \"X\" and trouver_case18(\"RMK/\", x[\"case18\"]) != \"EVASAN\":\n",
        "#                             x['PLN_valide'] = trouver_case18\n",
        "#                             x['invalidite_TU'].append(\"EXO12\")\n",
        "#             else:\n",
        "#                 if trouver_case18(\"RMK/\", x[\"case18\"]) == \"TRAINING\" and x['vol_interieur'] == True and (x[\"code_d_exoneration\"] == \"Y\" or [\"code_d_exoneration\"] == \"Z\"):\n",
        "#                     x[\"code_d_exoneration\"] = \"T\"\n",
        "\n",
        "#     df_utile = df_utile.apply(TU_7_element, axis=1)\n",
        "#     return df_utile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "oSHceEAhK9-l"
      },
      "outputs": [],
      "source": [
        "def TU_7(df_utile):\n",
        "    def TU_7_element(x):\n",
        "        # Fonction pour trouver une valeur valide dans les colonnes multiples\n",
        "        def get_valid_value(element, columns):\n",
        "            for col in columns:\n",
        "                if col in element and not(element[[col]].isna().iloc[0]):\n",
        "                    return element[col]\n",
        "            return None\n",
        "\n",
        "        PLN_active_value = get_valid_value(x, [\"plnActive_realise\", \"plnActive_final\", \"plnActive_prevu\"])\n",
        "        call_sign_value = get_valid_value(x, [\"callSign_realise\", \"callSign_final\", \"callSign_prevu\"])\n",
        "        type_vol_value = get_valid_value(x, [\"typeVol_realise\", \"typeVol_final\", \"typeVol_prevu\"])\n",
        "\n",
        "        if PLN_active_value == \"0\" and x.get('vol_a_transmettre', False):\n",
        "            x['PLN_valide'] = False\n",
        "\n",
        "        if call_sign_value in [\"APL\", \"FPL\"]:\n",
        "            if x.get('vol_a_transmettre', False):\n",
        "                if code_exoneration_value in [\"Y\", \"Z\"]:\n",
        "                    if type_vol_value == \"M\":\n",
        "                        x['PLN_valide'] = False\n",
        "                        x['invalidite_TU'].extend([\"EXO10\", \"OPR10\"])\n",
        "                    else:\n",
        "                        if trouver_case18(\"RMK/\", x[\"case18\"]) == \"TRAINING\" and x.get('vol_interieur', False):\n",
        "                            x[\"code_d_exoneration\"] = \"T\"\n",
        "                        elif type_vol_value == \"X\" and trouver_case18(\"RMK/\", x[\"case18\"]) != \"EVASAN\":\n",
        "                            x['PLN_valide'] = False\n",
        "                            x['invalidite_TU'].append(\"EXO12\")\n",
        "            else:\n",
        "                if trouver_case18(\"RMK/\", x[\"case18\"]) == \"TRAINING\" and x.get('vol_interieur', False) and code_exoneration_value in [\"Y\", \"Z\"]:\n",
        "                    x[\"code_d_exoneration\"] = \"T\"\n",
        "        return x\n",
        "    df_utile = df_utile.apply(TU_7_element, axis=1)\n",
        "    return df_utile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT6zx5gh9Oth"
      },
      "source": [
        "## Traitement unitaire complet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "MDuug6-bOkY0"
      },
      "outputs": [],
      "source": [
        "def traitement_unitaire(df_utile):\n",
        "    df_utile = TU_init(df_utile)\n",
        "    df_utile = TU_1(df_utile)\n",
        "    df_utile = TU_2(df_utile)\n",
        "\n",
        "    def check_depfinal_prefix(row):\n",
        "        for col in [\"dep_realise\", \"dep_final\", \"dep_prevu\"]:\n",
        "            if col in row and not pd.isna(row[col]) and row[col] != \"\":\n",
        "                if row[col][:2] == \"LF\":\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def apply_transformations(row):\n",
        "        if check_depfinal_prefix(row):\n",
        "            return TU_4(pd.DataFrame([row])).iloc[0]\n",
        "        else:\n",
        "            return TU_3_bis(pd.DataFrame([row])).iloc[0]\n",
        "\n",
        "    # Appliquer les transformations par ligne\n",
        "    df_utile = df_utile.apply(apply_transformations, axis=1)\n",
        "\n",
        "    df_utile = TU_5(df_utile)\n",
        "    df_utile = TU_6(df_utile)\n",
        "    df_utile = TU_7(df_utile)\n",
        "    return df_utile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBDe4ThtDTjX"
      },
      "source": [
        "# Transformation des données RDVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "M5Vur2_oPlRg"
      },
      "outputs": [],
      "source": [
        "jour_1_utile_inutile = traitement_utile_inutile(jour_1)\n",
        "jour_2_utile_inutile = traitement_utile_inutile(jour_2)\n",
        "jour_3_utile_inutile = traitement_utile_inutile(jour_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "u34pJDL5PgxN"
      },
      "outputs": [],
      "source": [
        "jour_1_utile = jour_1_utile_inutile[jour_1_utile_inutile[\"utile_inutile\"] == \"UTI\"].copy()\n",
        "jour_2_utile = jour_2_utile_inutile[jour_2_utile_inutile[\"utile_inutile\"] == \"UTI\"].copy()\n",
        "jour_3_utile = jour_3_utile_inutile[jour_3_utile_inutile[\"utile_inutile\"] == \"UTI\"].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kPxnmT3QjY_o"
      },
      "outputs": [],
      "source": [
        "jour_1_utile_traitee = traitement_unitaire(jour_1_utile)\n",
        "jour_2_utile_traitee = traitement_unitaire(jour_2_utile)\n",
        "jour_3_utile_traitee = traitement_unitaire(jour_3_utile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L0PPiECOJ48"
      },
      "source": [
        "Fonction\n",
        "ajouter pour chaque df une colonne doublon à False\n",
        "Verifier que si un call sign et une heure de reference à 19mn pret (à parametrer) indiquer doublon sur l'un des vols seulement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "VHexroXEOJ49"
      },
      "outputs": [],
      "source": [
        "seuil_doublon = 19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "AQfLW-HtOJ49"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def ajouter_colonne_doublon(df, tolerance_minutes=19):\n",
        "    df['doublon'] = False\n",
        "\n",
        "    df = df.sort_values(by=['callSign_prevu', 'heure_de_reference']).reset_index(drop=True)\n",
        "    i = 1\n",
        "    while i < len(df):\n",
        "        if df.at[i, 'callSign_prevu'] == df.at[i - 1, 'callSign_prevu']:\n",
        "            delta = abs((df.at[i, 'heure_de_reference'] - df.at[i - 1, 'heure_de_reference']))\n",
        "            if delta <= tolerance_minutes:\n",
        "                df = df.drop(i).reset_index(drop=True)\n",
        "                continue  # Réévaluer le même index i après la suppression et la réinitialisation de l'index\n",
        "        i += 1\n",
        "    return df\n",
        "\n",
        "def supprimer_doublons(df):\n",
        "    return df[df['doublon'] == False].drop(columns=['doublon'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ai4jSagOJ4-",
        "outputId": "e6da8d07-f6af-4950-bc3a-ce6ed3002b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-b3b8304d8a7f>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['doublon'] = False\n",
            "<ipython-input-41-b3b8304d8a7f>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['doublon'] = False\n",
            "<ipython-input-41-b3b8304d8a7f>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['doublon'] = False\n"
          ]
        }
      ],
      "source": [
        "jour_1_utile_traitee_avec_doublons_false = ajouter_colonne_doublon(jour_1_utile_traitee)\n",
        "jour_2_utile_traitee_avec_doublons_false = ajouter_colonne_doublon(jour_2_utile_traitee)\n",
        "jour_3_utile_traitee_avec_doublons_false = ajouter_colonne_doublon(jour_3_utile_traitee)\n",
        "\n",
        "jour_1_utile_traitee_sans_doublons = supprimer_doublons(jour_1_utile_traitee_avec_doublons_false)\n",
        "jour_2_utile_traitee_sans_doublons = supprimer_doublons(jour_2_utile_traitee_avec_doublons_false)\n",
        "jour_3_utile_traitee_sans_doublons = supprimer_doublons(jour_3_utile_traitee_avec_doublons_false)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "HNgPuXKKUIrK"
      },
      "outputs": [],
      "source": [
        "def get_valid_value(element, columns):\n",
        "        for col in columns:\n",
        "            if col in element and not(element[[col]].isna().iloc[0]):\n",
        "                return element[col]\n",
        "        return \"\"\n",
        "\n",
        "def format_flight_message(row):\n",
        "    sequence_number = f\"{row.name + 1:04}\"\n",
        "    intro_correction_code = \"F\"\n",
        "    valeur = int(get_valid_value(row, ['heure_de_reference']))\n",
        "    heure = (valeur%1440)//60\n",
        "    min = (valeur%1440)%60\n",
        "    time_of_departure = f\"{(100*heure + min):04}\"\n",
        "    aerodrome_of_departure = get_valid_value(row, ['dep_realise', 'dep_final', 'de_prevu']).ljust(4)\n",
        "    aerodrome_of_arrival = get_valid_value(row, ['arr_realise', 'arr_final', 'arr_prevu']).ljust(4)\n",
        "    flight_identification = get_valid_value(row, ['callSign_realise', 'callSign_final', 'callSign_prevu']).ljust(9)\n",
        "    main_exemption_code = row[\"code_d_exoneration\"].ljust(1)\n",
        "    aircraft_type = get_valid_value(row, ['typeAvion_realise', 'typeAvion_final', 'typeAvion_prevu']).ljust(7)\n",
        "    operator = str(row[\"code_exploitant\"]).ljust(3)\n",
        "    aircraft_registration = str(get_valid_value(row, ['work1realise', 'work1final', 'work1prevu'])).ljust(9)\n",
        "    comment = \"\"\n",
        "    est_off_block_date = get_valid_value(row, ['date_de_reference']).ljust(6)\n",
        "    ifplid = get_valid_value(row, ['IFPL_realise', 'IFPL_final', 'IFPL_prevu']).ljust(9)\n",
        "    initial_aerodrome_destination = \"\"\n",
        "    charging_zone_overflown = \"\"\n",
        "    entry_point_coordinates = \"\"\n",
        "    exit_point_coordinates = \"\"\n",
        "    supplementary_exemption_codes = \"\"\n",
        "    source_icao_address = \"\"\n",
        "    icao_address = get_valid_value(row, ['adresseModeS_realise', 'adresseModeS_final', 'adresseModeS_prevu']).ljust(6)\n",
        "    additional_comment = \"\"\n",
        "    front_alg_fr = row[\"front_alg_fr\"]\n",
        "    premier_plot_fr = str(row[\"premier_plot_fr\"])\n",
        "    modes_fr = str(row[\"modes_fr\"])\n",
        "\n",
        "    return {\n",
        "        \"Sequence number\": sequence_number,\n",
        "        \"Code\": intro_correction_code,\n",
        "        \"Time of departure/entry\": time_of_departure,\n",
        "        \"Departure aerodrome\": aerodrome_of_departure,\n",
        "        \"Arrival aerodrome\": aerodrome_of_arrival,\n",
        "        \"Flight identification\": flight_identification,\n",
        "        \"Main Exemption code\": main_exemption_code,\n",
        "        \"Type of aircraft\": aircraft_type,\n",
        "        \"Operator\": operator,\n",
        "        \"Aircraft Registration\": aircraft_registration,\n",
        "        \"Comment1\": comment,\n",
        "        \"Flight date\": est_off_block_date,\n",
        "        \"IFPLID\": ifplid,\n",
        "        \"Planned_aerodrome\": initial_aerodrome_destination,\n",
        "        \"Charging_zone_overflow\": charging_zone_overflown,\n",
        "        \"Entry_point\": entry_point_coordinates,\n",
        "        \"Exit_point\": exit_point_coordinates,\n",
        "        \"Sup_exemption_code\": supplementary_exemption_codes,\n",
        "        \"Source of the Aircraft Address\": source_icao_address,\n",
        "        \"24-bit Aircraft Address\": icao_address,\n",
        "        \"Comment2\": additional_comment,\n",
        "        \"case7\" : str(row[\"case7\"]),\n",
        "        \"case8\" : str(row[\"case8\"]),\n",
        "        \"case9\" : str(row[\"case9\"]),\n",
        "        \"case10\" : str(row[\"case10\"]),\n",
        "        \"case13\" : str(row[\"case13\"]),\n",
        "        \"case15\" : str(row[\"case15\"]),\n",
        "        \"case16\" : str(row[\"case16\"]),\n",
        "        \"case18\" : str(row[\"case18\"]),\n",
        "        \"ccrArrival\" : str(row[\"ccrArrival\"]),\n",
        "        \"front_alg_fr\" : front_alg_fr,\n",
        "        \"premier_plot_fr\" : premier_plot_fr,\n",
        "        \"modes_fr\" : modes_fr\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Z9bvXt-VYY2x"
      },
      "outputs": [],
      "source": [
        "jour_123 = pd.concat([jour_1_utile_traitee_avec_doublons_false, jour_2_utile_traitee_avec_doublons_false, jour_3_utile_traitee_avec_doublons_false], ignore_index=True)\n",
        "jour_123['date_de_reference'] = jour_123['date_de_reference'].dt.strftime('%y%m%d')\n",
        "jour_123 = jour_123[jour_123[\"vol_a_transmettre\"] == True]\n",
        "target_date_str =dateAnalyse\n",
        "target_date = datetime.strptime(target_date_str, \"%d-%m-%Y\")\n",
        "target_date_str = target_date.strftime(\"%y%m%d\")\n",
        "jour_cible = jour_123[(jour_123[\"date_de_reference\"] == target_date_str) | (jour_123[\"date_de_reference\"] == \"      \")]\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = jour_cible.copy()"
      ],
      "metadata": {
        "id": "XNJkuxrlfl05"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jour_cible = data.copy()"
      ],
      "metadata": {
        "id": "jdfzL9pQqx5E"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nom_fichier_survol = f'data_survols_{datetime.strptime(dateAnalyse, \"%d-%m-%Y\").strftime(\"%Y%m%d\")}.csv'\n",
        "data_survols = pd.read_csv(nom_fichier_survol, sep=',')\n",
        "def conversion_dec_hexa(number):\n",
        "    if number != number:  # Vérification pour NaN\n",
        "        return 'NaN'\n",
        "    else:\n",
        "        hex_value = hex(int(number))[2:].upper()\n",
        "        return hex_value.zfill(6)\n",
        "data_survols['MODES_ADRESS'] = data_survols['MODES_ADRESS'].apply(conversion_dec_hexa)\n",
        "# Créer les colonnes front_alg_fr, premier_plot_fr, modes_fr avec des NaN\n",
        "jour_cible['front_alg_fr'] = np.nan\n",
        "jour_cible['premier_plot_fr'] = np.nan\n",
        "jour_cible['modes_fr'] = np.nan\n",
        "\n",
        "# Parcourir chaque ligne de jour_cible\n",
        "for i, row in jour_cible.iterrows():\n",
        "    # Filtrer data_survols pour trouver les lignes où les critères sont respectés\n",
        "    matched_rows = data_survols[\n",
        "        (row['callSign_prevu'] == data_survols['FLPL_CALL_SIGN']) &\n",
        "        (abs((100*(row['heure_de_reference']%1440)//60 + (row['heure_de_reference']%1440)%60) - data_survols['premier_plot']) < 500)\n",
        "        # (row['arr_prevu'] == data_survols['FLPL_ARRV_AIRP'])\n",
        "    ]\n",
        "\n",
        "    if not matched_rows.empty:\n",
        "        # Si une correspondance est trouvée, prendre la première (ou vous pouvez choisir une autre règle)\n",
        "        match = matched_rows.iloc[0]\n",
        "\n",
        "        # Mettre à jour les colonnes de jour_123\n",
        "        jour_cible.at[i, 'front_alg_fr'] = match['frontiere_algerienne']\n",
        "        jour_cible.at[i, 'premier_plot_fr'] = match['premier_plot']\n",
        "        jour_cible.at[i, 'modes_fr'] = match['MODES_ADRESS']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCuzbMG1gXxG",
        "outputId": "74d5618d-ff77-421b-d1e0-b7d3ac5b8e81"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-96-a4be6d360df2>:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  jour_cible.at[i, 'front_alg_fr'] = match['frontiere_algerienne']\n",
            "<ipython-input-96-a4be6d360df2>:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '4D4038' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  jour_cible.at[i, 'modes_fr'] = match['MODES_ADRESS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jour_cible = jour_cible.apply(format_flight_message, axis=1).tolist()\n",
        "jour_cible = pd.DataFrame(jour_cible)\n",
        "jour_cible['Time of departure/entry'] = pd.to_numeric(jour_cible['Time of departure/entry'], errors='coerce')"
      ],
      "metadata": {
        "id": "TlIbtIBVPLam"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeS1 = pd.read_csv(os.path.join(chemin_dossier_table_systeme,\"modeS1\"), sep=';', skiprows=3)\n",
        "modeS1 = modeS1[['Mode S', 'Type Avion']]\n",
        "modeS1.rename(columns={\n",
        "    'Type Avion': 'Type Avion Survol'\n",
        "}, inplace=True)\n",
        "\n",
        "\n",
        "jour_cible['Type_Avion_Survol'] = np.nan\n",
        "# Parcourir chaque ligne de jour_cible\n",
        "for i, row in jour_cible.iterrows():\n",
        "    # Filtrer data_survols pour trouver les lignes où les critères sont respectés\n",
        "    matched_rows = modeS1[\n",
        "        (row['modes_fr'] == modeS1['Mode S'])\n",
        "    ]\n",
        "\n",
        "    if not matched_rows.empty:\n",
        "        # Si une correspondance est trouvée, prendre la première (ou vous pouvez choisir une autre règle)\n",
        "        match = matched_rows.iloc[0]\n",
        "        # Mettre à jour les colonnes de jour_cible\n",
        "        jour_cible.at[i, 'Type_Avion_Survol'] = match['Type Avion Survol']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyyOYFicq95F",
        "outputId": "d32eea49-e249-4c18-d339-569b9a707bde"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-98-71b8084d1254>:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'C525' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  jour_cible.at[i, 'Type_Avion_Survol'] = match['Type Avion Survol']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Sauvegarder le DataFrame en fichier CSV\n",
        "jour_cible.to_csv('jour_cible_FR.csv', index=False)\n",
        "\n",
        "# Télécharger le fichier CSV sur votre ordinateur local\n",
        "files.download('jour_cible_FR.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sM77RX-XpGjp",
        "outputId": "bd369c94-00c6-4af6-89f8-efec39bc466d"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ba046678-996e-4e80-bdfc-3b90ec582553\", \"jour_cible_FR.csv\", 1043639)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jour_cible.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnJcj0_1MV3P",
        "outputId": "92787a3f-c96f-43a7-9f00-54f8e06767a2"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2535"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jour_cible[(jour_cible['24-bit Aircraft Address'] == \"      \")].shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeCStz3iMYPR",
        "outputId": "174461f8-34f8-4c2e-e50d-b5e96041e6bb"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jour_cible[(jour_cible['modes_fr'] == \"nan\") & (jour_cible['24-bit Aircraft Address'] == \"      \")].shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YTzIDbeLdUW",
        "outputId": "fd868a80-35f5-429d-8e48-00342b7aabd7"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fc8aGUSJMb-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jour_123 = pd.read_csv(\"jour_cible_FR.csv\")"
      ],
      "metadata": {
        "id": "mVBmbM2pknNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abacus analyse mode S"
      ],
      "metadata": {
        "id": "BCDcxlvoMqw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fonction"
      ],
      "metadata": {
        "id": "VJKTDH96M-r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_valid_value(element, columns):\n",
        "        for col in columns:\n",
        "            if col in element and not(element[[col]].isna().iloc[0]):\n",
        "                return element[col]\n",
        "        return \"\"\n",
        "\n",
        "def format_flight_message2(row):\n",
        "    sequence_number = f\"{row.name + 1:04}\"\n",
        "    intro_correction_code = \"F\"\n",
        "    time_of_departure = f\"{(int(get_valid_value(row, ['Time of departure/entry']))):04}\"\n",
        "    aerodrome_of_departure = get_valid_value(row, ['Departure aerodrome']).ljust(4)\n",
        "    aerodrome_of_arrival = get_valid_value(row, ['Arrival aerodrome']).ljust(4)\n",
        "    flight_identification = get_valid_value(row, ['Flight identification']).ljust(9)\n",
        "    main_exemption_code = row['Main Exemption Code'].ljust(1)\n",
        "    aircraft_type = get_valid_value(row, ['Type of aircraft']).ljust(7)\n",
        "    operator = row['Main Exemption Code'].ljust(3)\n",
        "    aircraft_registration = get_valid_value(row, ['Aircraft Registration']).ljust(9)\n",
        "    comment = \"\"\n",
        "    est_off_block_date = str(get_valid_value(row, ['Flight date'])).ljust(6)\n",
        "    ifplid = get_valid_value(row, ['IFPLID']).ljust(9)\n",
        "    initial_aerodrome_destination = \"\"\n",
        "    charging_zone_overflown = \"\"\n",
        "    entry_point_coordinates = \"\"\n",
        "    exit_point_coordinates = \"\"\n",
        "    supplementary_exemption_codes = \"\"\n",
        "    source_icao_address = row['Source of the Aircraft Address']\n",
        "    icao_address = row['24-bit Aircraft Address']\n",
        "    additional_comment = \"\"\n",
        "\n",
        "    return {\n",
        "        \"Sequence number\": sequence_number,\n",
        "        \"Code\": intro_correction_code,\n",
        "        \"Time of departure/entry\": time_of_departure,\n",
        "        \"Departure aerodrome\": aerodrome_of_departure,\n",
        "        \"Arrival aerodrome\": aerodrome_of_arrival,\n",
        "        \"Flight identification\": flight_identification,\n",
        "        \"Main Exemption code\": main_exemption_code,\n",
        "        \"Type of aircraft\": aircraft_type,\n",
        "        \"Operator\": operator,\n",
        "        \"Aircraft Registration\": aircraft_registration,\n",
        "        \"Comment1\": comment,\n",
        "        \"Flight date\": est_off_block_date,\n",
        "        \"IFPLID\": ifplid,\n",
        "        \"Planned_aerodrome\": initial_aerodrome_destination,\n",
        "        \"Charging_zone_overflow\": charging_zone_overflown,\n",
        "        \"Entry_point\": entry_point_coordinates,\n",
        "        \"Exit_point\": exit_point_coordinates,\n",
        "        \"Sup_exemption_code\": supplementary_exemption_codes,\n",
        "        \"Source of the Aircraft Address\": source_icao_address,\n",
        "        \"24-bit Aircraft Address\": icao_address,\n",
        "        \"Comment2\": additional_comment\n",
        "    }"
      ],
      "metadata": {
        "id": "JZxHDaroM56S"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyse"
      ],
      "metadata": {
        "id": "oTvoTW_sNCkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "liste_noms_colonnes = ['Origin of message','Flight date','Sequence number','Time of departure/entry','Departure aerodrome','Arrival aerodrome','Type of aircraft','Flight identification','Aircraft Registration','User ICAO Code','User Number','VAT Number','User Nationality','Correction Code','IFPLID','24-bit Aircraft Address','Source of the Aircraft Address','Main Exemption Code','1st Supp. Ex. Code','2nd Supp. Ex. Code','3rd Supp. Ex. Code','Flight Message ID','Claim Number','Pro forma number','Pro forma line number','Bill or Credit Note Reference','MTOW','Weight Coefficient','Distance Coefficient','Service Units','National Route Charge in BZ','Admin. Route Charge in BZ','National Route Charge for SP','Admin. Route Charge for SP','Exemption Indicator','Exemption Code','Flight category','VAT Doc. Ref.','Original VAT Doc. Ref','VAT Rate','VAT Code','VAT on National Route Charge for SP','VAT on Admin. Route Charge for SP']\n",
        "ABACUS_Mars = pd.read_csv(os.path.join(chemin_dossier_abacus,'LF20LF10_S_ABACUS_FLSPBZ03_2403.TXT'), sep=';', usecols = liste_noms_colonnes)\n",
        "ABACUS = ABACUS_Mars[(ABACUS_Mars[\"Flight date\"] == int(target_date_str)) & (ABACUS_Mars[\"Origin of message\"] == \"LF\")]\n",
        "ABACUS = ABACUS.apply(format_flight_message2, axis=1).tolist()\n",
        "ABACUS = pd.DataFrame(ABACUS)\n",
        "ABACUS['Time of departure/entry'] = pd.to_numeric(ABACUS['Time of departure/entry'], errors='coerce')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFM66qYPMt6W",
        "outputId": "ef659f8a-a9c6-4a72-db66-cd367c009536"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-cca42e35ec81>:2: DtypeWarning: Columns (18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  ABACUS_Mars = pd.read_csv(os.path.join(chemin_dossier_abacus,'LF20LF10_S_ABACUS_FLSPBZ03_2403.TXT'), sep=';', usecols = liste_noms_colonnes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ABACUS.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neZO7K_PNafh",
        "outputId": "4eb1bc49-6c20-4f72-b202-a375d52c6127"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2456"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ABACUS[(ABACUS['24-bit Aircraft Address'] == \"nan\")].shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u7ODNdYNbCf",
        "outputId": "3d3fa6b3-a3a7-440b-fa47-4424c06bd6db"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ABACUS[ABACUS[\"24-bit Aircraft Address\"].isna()].shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVtX3D8FNiIK",
        "outputId": "7cf87af3-3559-474d-81f5-41f47940322f"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EBtgOoViwUy-",
        "souikmud3lfh",
        "VJKTDH96M-r2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}